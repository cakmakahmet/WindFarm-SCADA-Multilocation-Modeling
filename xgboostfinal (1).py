# -*- coding: utf-8 -*-
"""XGBoostFinal.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15fPXEK-JAhaNkfr4bjH-dVbFh49d3USP
"""

XGBoost + FE + normalize edilmiş dataset

import pandas as pd
import numpy as np
import time
from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

from google.colab import drive
drive.mount('/content/drive')

test_size = 0.2
dosya_yolu =  "/content/All_Combined.csv"
data = pd.read_csv(dosya_yolu, parse_dates=["Time"])

gr = data.groupby("Location", group_keys=False)
data["Power_lag1"] = gr["Power"].shift(1)
data["Power_lag24"] = gr["Power"].shift(24)
data["Power_rollmean3"] = gr["Power"].shift(1).rolling(3).mean()
data["Power_rollmeansdt3"] = gr["Power"].shift(1).rolling(24).mean()

data["hour"] = data["Time"].dt.hour
data["dayofweek"] = data["Time"].dt.dayofweek
data["month"] = data["Time"].dt.month

X = data.drop(columns=["Time", "Power"]).copy()
y = data["Power"].copy()

obje_kolonlar = X.select_dtypes(include=["object"])
if len(obje_kolonlar) > 0:
  X[obje_kolonlar] = X[obje_kolonlar].apply(pd.to_numeric, errors="coerce")
X = X.replace([np.inf, -np.inf], np.nan)
maske = X.notna().all(axis=1) & y.notna()
X = X.loc[maske].reset_index(drop=True)
y = y.loc[maske].reset_index(drop=True)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=test_size, shuffle=False
)
print(f"Eğitim seti boyutu (X_train): {X_train.shape[0]}")
print(f"Test seti boyutu (X_test): {X_test.shape[0]}\n")

xgb = XGBRegressor(
    n_estimators=800,
    learning_rate=0.05,
    max_depth=6,
    subsample=0.9,
    colsample_bytree=0.9,
    objective="reg:squarederror",
    random_state=42,
    n_jobs=-1
)

start_time = time.time()
xgb.fit(X_train, y_train)
end_time = time.time()
print(f"Eğitim tamamlandı. Süre:{end_time - start_time: .2f} saniye")

y_pred_xgb = xgb.predict(X_test)
mae_xgb = mean_absolute_error(y_test, y_pred_xgb)
rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))
r2_xgb = r2_score(y_test, y_pred_xgb)

print("\n XGBoost Model Metrikleri ")
print(f"MAE (Ort. Mutlak Hata):  {mae_xgb:.6f}")
print(f"RMSE (K.K. Ort. Hata): {rmse_xgb:.6f}")
print(f"R² (Belirleme Katsayısı):   {r2_xgb:.4f}")

"""XGBoost + NOT FE + normalize edilmiş dataset"""

import pandas as pd
import numpy as np
import time
from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

from google.colab import drive
drive.mount('/content/drive')

test_size = 0.2
dosya_yolu =  "/content/All_Combined.csv"
data = pd.read_csv(dosya_yolu, parse_dates=["Time"])

X = data.drop(columns=["Time", "Power"]).copy()
y = data["Power"].copy()

obje_kolonlar = X.select_dtypes(include=["object"])
if len(obje_kolonlar) > 0:
  X[obje_kolonlar] = X[obje_kolonlar].apply(pd.to_numeric, errors="coerce")
X = X.replace([np.inf, -np.inf], np.nan)
maske = X.notna().all(axis=1) & y.notna()
X = X.loc[maske].reset_index(drop=True)
y = y.loc[maske].reset_index(drop=True)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=test_size, shuffle=False
)
print(f"Eğitim seti boyutu (X_train): {X_train.shape[0]}")
print(f"Test seti boyutu (X_test): {X_test.shape[0]}\n")

xgb = XGBRegressor(
    n_estimators=800,
    learning_rate=0.05,
    max_depth=6,
    subsample=0.9,
    colsample_bytree=0.9,
    objective="reg:squarederror",
    random_state=42,
    n_jobs=-1
)

start_time = time.time()
xgb.fit(X_train, y_train)
end_time = time.time()
print(f"Eğitim tamamlandı. Süre:{end_time - start_time: .2f} saniye")

y_pred_xgb = xgb.predict(X_test)
mae_xgb = mean_absolute_error(y_test, y_pred_xgb)
rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))
r2_xgb = r2_score(y_test, y_pred_xgb)

print("\n XGBoost Model Metrikleri ")
print(f"MAE (Ort. Mutlak Hata):  {mae_xgb:.6f}")
print(f"RMSE (K.K. Ort. Hata): {rmse_xgb:.6f}")
print(f"R² (Belirleme Katsayısı):   {r2_xgb:.4f}")

XGBoost + FE + direkt SCADA türbin verisinin meteorolojik verilerle çeşitlendirilmiş hali

from google.colab import drive
drive.mount('/content/drive')

dosya_yolu = "/content/T1_merged_meteo.csv"

df = pd.read_csv(dosya_yolu)
print("Ham veri şekli:", df.shape)
print("Sütunlar:", df.columns.tolist())

df["Time"] = pd.to_datetime(df["Time"])
df = df.sort_values("Time").reset_index(drop=True)

# FEATURE ENGINEERING

data = df.copy()

# İsimleri standardize et
data = data.rename(columns={
    "LV ActivePower (kW)": "Power",
    "Date/Time": "Time"   # yoksa bir şey olmaz
})

# Time kolonunu garantiye al
data["Time"] = pd.to_datetime(data["Time"])

print("Başlangıç shape:", data.shape)

# Start/stop gürültüsü filtresi
# Gerekirse eşiği düşürebiliriz (örn. > 10)
data = data[data["Power"] > 50]
print("Power>50 filtresi sonrası:", data.shape)

# Power türev ve lag'ler
data["dPower"]      = data["Power"].diff()
data["Power_lag1"]  = data["Power"].shift(1)
data["Power_lag6"]  = data["Power"].shift(6)      # ~1 saat
data["Power_lag24"] = data["Power"].shift(24)     # ~4 saat

# Rolling ortalama / std
data["Power_roll6"] = (
    data["Power"]
      .shift(1)
      .rolling(6)
      .mean()
)

data["Power_roll12"] = (
    data["Power"]
      .shift(1)
      .rolling(12)
      .mean()
)

data["Power_rollstd6"] = (
    data["Power"]
      .shift(1)
      .rolling(6)
      .std()
)

#Rüzgar hızı feature'ları
if "Wind Speed (m/s)" in data.columns:
    data["dWind"] = data["Wind Speed (m/s)"].diff()

    data["Wind_rollmean3"] = (
        data["Wind Speed (m/s)"]
          .shift(1)
          .rolling(3)
          .mean()
    )

    data["Wind_rollstd3"] = (
        data["Wind Speed (m/s)"]
          .shift(1)
          .rolling(3)
          .std()
    )

    data["Wind3"] = data["Wind Speed (m/s)"] ** 3

# Rüzgar yönü sin/cos
if "Wind Direction (°)" in data.columns:
    data["wind_sin"] = np.sin(np.deg2rad(data["Wind Direction (°)"]))
    data["wind_cos"] = np.cos(np.deg2rad(data["Wind Direction (°)"]))

# Zaman feature'ları
data["hour"]      = data["Time"].dt.hour
data["dayofweek"] = data["Time"].dt.dayofweek
data["month"]     = data["Time"].dt.month
data["dayofyear"] = data["Time"].dt.dayofyear

# ERA5 meteo feature'ları (varsa)
if "windspeed_100m" in data.columns:
    data["era_ws100"]   = data["windspeed_100m"]
    data["era_ws100_3"] = data["windspeed_100m"] ** 3

if "windspeed_10m" in data.columns:
    data["era_ws10"] = data["windspeed_10m"]

if "winddirection_10m" in data.columns:
    data["era_wd_sin"] = np.sin(np.deg2rad(data["winddirection_10m"]))
    data["era_wd_cos"] = np.cos(np.deg2rad(data["winddirection_10m"]))

if "windgusts_10m" in data.columns:
    data["era_gust"] = data["windgusts_10m"]

if "temperature_2m" in data.columns:
    data["era_temp2"] = data["temperature_2m"]

if "relativehumidity_2m" in data.columns:
    data["era_rh2"] = data["relativehumidity_2m"]

if "dewpoint_2m" in data.columns:
    data["era_dew2"] = data["dewpoint_2m"]

# Hava yoğunluğu
R = 287.05
if "pressure_msl" in data.columns and "temperature_2m" in data.columns:
    data["air_density"] = (data["pressure_msl"] * 100) / (R * (data["temperature_2m"] + 273.15))

# Tamamen NaN kolonları temizle
# (örneğin tüm satırlarda NaN olan 80m vs. kolonları otomatik siler)
data = data.dropna(axis=1, how="all")

# Lag/rolling nedeniyle ilk örnekleri at
# En büyük lag 24 olduğu için ilk 24 satırı güvenli şekilde atıyoruz
data = data.iloc[24:].copy()

# Kalan NaN'leri satır bazında temizle
data = data.dropna().reset_index(drop=True)

print("FE sonrası veri şekli:", data.shape)
print("Kalan kolon sayısı:", len(data.columns))
print("Kolonlar:", data.columns.tolist())

# X, y OLUŞTURMA ve TRAIN / VAL / TEST AYRIMI

hedef_sutun = "Power"
tarih_sutun = "Time"

# Özellik kolonları: zaman ve hedef hariç her şey
ozellik_sutunlar = [c for c in data.columns if c not in [hedef_sutun, tarih_sutun]]

X = data[ozellik_sutunlar].values
y = data[hedef_sutun].values

n = len(data)
train_end = int(n * 0.70)
val_end   = int(n * 0.85)   # %70 train, %15 val, %15 test

X_train, y_train = X[:train_end], y[:train_end]
X_val,   y_val   = X[train_end:val_end], y[train_end:val_end]
X_test,  y_test  = X[val_end:], y[val_end:]

print(f"Toplam örnek sayısı: {n}")
print(f"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}")
print("Özellik sayısı:", X_train.shape[1])

import time

# 6) XGBOOST MODELİNİ OLUŞTUR VE EĞİT

xgb = XGBRegressor(
    n_estimators=800,
    learning_rate=0.05,
    max_depth=6,
    subsample=0.9,
    colsample_bytree=0.9,
    objective="reg:squarederror",
    random_state=42,
    n_jobs=-1
)

start_time = time.time()
xgb.fit(X_train, y_train)
end_time = time.time()
print(f"Eğitim tamamlandı. Süre:{end_time - start_time: .2f} saniye")

y_pred = xgb.predict(X_test)

mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = mse ** 0.5
r2 = r2_score(y_test, y_pred)

print(" XGBoost Sonuçları")
print(f"MAE : {mae:.3f}")
print(f"RMSE: {rmse:.3f}")
print(f"R²  : {r2:.4f}")

def evaluate(name, y_true, y_pred):
    mae  = mean_absolute_error(y_true, y_pred)
    rmse = mean_squared_error(y_true, y_pred) ** 0.5
    r2   = r2_score(y_true, y_pred)
    print(f"{name:<10} → MAE: {mae:.3f}, RMSE: {rmse:.3f}, R2: {r2:.4f}")

# VALIDATION
y_val_pred = xgb.predict(X_val)
print(" VALIDATION SONUÇLARI")
evaluate("XGBoost (val)", y_val, y_val_pred)

# TEST
y_test_pred = xgb.predict(X_test)
print("\n TEST SONUÇLARI")
evaluate("XGBoost (test)", y_test, y_test_pred)

from xgboost import XGBRegressor

base_params = dict(
    n_estimators=300,
    learning_rate=0.05,
    max_depth=3,
    subsample=0.9,
    colsample_bytree=0.9,
    random_state=42,
    n_jobs=-1
)

xgb_q10 = XGBRegressor(
    objective="reg:quantileerror",
    quantile_alpha=0.10,
    **base_params
)

xgb_q50 = XGBRegressor(
    objective="reg:quantileerror",
    quantile_alpha=0.50,
    **base_params
)

xgb_q90 = XGBRegressor(
    objective="reg:quantileerror",
    quantile_alpha=0.90,
    **base_params
)

xgb_q10.fit(X_train, y_train)
xgb_q50.fit(X_train, y_train)
xgb_q90.fit(X_train, y_train)

y_q10 = xgb_q10.predict(X_test)
y_q50 = xgb_q50.predict(X_test)
y_q90 = xgb_q90.predict(X_test)

y_q10 = xgb_q10.predict(X_test)
y_q50 = xgb_q50.predict(X_test)
y_q90 = xgb_q90.predict(X_test)

from sklearn.metrics import mean_absolute_error

y_pred_point = xgb.predict(X_test)   # senin normal modelin
mae_point = mean_absolute_error(y_test, y_pred_point)
mae_q50 = mean_absolute_error(y_test, y_q50)

print("Normal XGB MAE:", mae_point)
print("Quantile q=0.50 MAE:", mae_q50)

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

# Eski (squarederror) XGB modelinden test tahmini
y_pred_point = xgb.predict(X_test)

# Quantile q=0.5 modelinden tahmin
y_pred_q50 = y_q50

def evaluate(name, y_true, y_pred):
    mae = mean_absolute_error(y_true, y_pred)
    rmse = mean_squared_error(y_true, y_pred) ** 0.5
    r2 = r2_score(y_true, y_pred)
    print(f"{name:15} → MAE: {mae:.5f}, RMSE: {rmse:.5f}, R²: {r2:.5f}")

evaluate("XGB point", y_test, y_pred_point)
evaluate("XGB q=0.5", y_test, y_pred_q50)

# %90 bandının gerçek kapsaması

inside_band = (y_test >= y_q10) & (y_test <= y_q90)
coverage = inside_band.mean() * 100

print(f"%90 bandının gerçek kapsaması: %{coverage:.2f}")

"""XGBoost + NOT FE + direkt SCADA türbin verisinin meteorolojik verilerle çeşitlendirilmiş hali"""

import numpy as np
import pandas as pd

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from xgboost import XGBRegressor

df = pd.read_csv("/content/T1_merged_meteo.csv")

# Time'ı datetime yap
df["Time"] = pd.to_datetime(df["Time"], errors="coerce")

print("Veri şekli:", df.shape)
print(df.head())

df = df.rename(columns={
    "LV ActivePower (kW)": "Power",
    "ActivePower": "Power",
    "Date/Time": "Time",
    "DATE_TIME": "Time"
})

hedef_sutun = "Power"
tarih_sutun = "Time"

# Time ve Power dışındaki her şeyi feature olarak al
X = df.drop(columns=[tarih_sutun, hedef_sutun]).copy()
y = df[hedef_sutun].copy()

#  X, y OLUŞTURMA

# Power ve Time dışındaki tüm feature'lar:
X = df.drop(columns=["Time", "Power"]).copy()
y = df["Power"].copy()

print("Başlangıç X shape:", X.shape)

# 1) Tamamen NaN kolonları sil
X = X.dropna(axis=1, how="all")
print("Tamamen NaN kolonlar temizlendi. X shape:", X.shape)

# 2) INF → NaN
X = X.replace([np.inf, -np.inf], np.nan)

# 3) Çok fazla NaN içeren kolonları sil (ör: %40'tan fazla)
threshold = 0.40
column_valid_ratio = X.notna().mean()

cols_to_drop = column_valid_ratio[column_valid_ratio < (1 - threshold)].index.tolist()
if len(cols_to_drop) > 0:
    print("Aşırı eksik kolonlar silindi:", cols_to_drop)
    X = X.drop(columns=cols_to_drop)

print("Eksik kolon temizliği sonrası X shape:", X.shape)

# 4) Satır bazlı NaN temizliği (ama tüm veriyi silmeyecek)
X = X.dropna().reset_index(drop=True)
y = y.loc[X.index]  # Y'yi de hizalıyoruz

print("Son temizlenmiş X shape:", X.shape)
print("Son temizlenmiş y shape:", y.shape)

n = len(X)
train_end = int(n * 0.70)
val_end   = int(n * 0.85)   # %70 train, %15 val, %15 test

X_train, y_train = X.iloc[:train_end].values, y.iloc[:train_end].values
X_val,   y_val   = X.iloc[train_end:val_end].values, y.iloc[train_end:val_end].values
X_test,  y_test  = X.iloc[val_end:].values, y.iloc[val_end:].values

print(f"Toplam örnek sayısı: {n}")
print(f"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}")
print("Özellik sayısı:", X_train.shape[1])

xgb = XGBRegressor(
    n_estimators=800,
    learning_rate=0.05,
    max_depth=6,
    subsample=0.9,
    colsample_bytree=0.9,
    objective="reg:squarederror",
    random_state=42,
    n_jobs=-1
)

start_time = time.time()
xgb.fit(X_train, y_train)
end_time = time.time()
print(f"Eğitim tamamlandı. Süre:{end_time - start_time: .2f} saniye")

y_pred = xgb.predict(X_test)

mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = mse ** 0.5
r2 = r2_score(y_test, y_pred)

print(" XGBoost Sonuçları")
print(f"MAE : {mae:.3f}")
print(f"RMSE: {rmse:.3f}")
print(f"R²  : {r2:.4f}")

def evaluate(name, y_true, y_pred):
    mae  = mean_absolute_error(y_true, y_pred)
    rmse = mean_squared_error(y_true, y_pred) ** 0.5
    r2   = r2_score(y_true, y_pred)
    print(f"{name:<10} → MAE: {mae:.3f}, RMSE: {rmse:.3f}, R2: {r2:.4f}")

# VALIDATION
y_val_pred = xgb.predict(X_val)
print("VALIDATION SONUÇLARI")
evaluate("XGBoost (val)", y_val, y_val_pred)

# TEST
y_test_pred = xgb.predict(X_test)
print("TEST SONUÇLARI")
evaluate("XGBoost (test)", y_test, y_test_pred)

from xgboost import XGBRegressor

base_params = dict(
    n_estimators=300,
    learning_rate=0.05,
    max_depth=3,
    subsample=0.9,
    colsample_bytree=0.9,
    random_state=42,
    n_jobs=-1
)

xgb_q10 = XGBRegressor(
    objective="reg:quantileerror",
    quantile_alpha=0.10,
    **base_params
)

xgb_q50 = XGBRegressor(
    objective="reg:quantileerror",
    quantile_alpha=0.50,
    **base_params
)

xgb_q90 = XGBRegressor(
    objective="reg:quantileerror",
    quantile_alpha=0.90,
    **base_params
)

xgb_q10.fit(X_train, y_train)
xgb_q50.fit(X_train, y_train)
xgb_q90.fit(X_train, y_train)

y_q10 = xgb_q10.predict(X_test)
y_q50 = xgb_q50.predict(X_test)
y_q90 = xgb_q90.predict(X_test)

y_q10 = xgb_q10.predict(X_test)
y_q50 = xgb_q50.predict(X_test)
y_q90 = xgb_q90.predict(X_test)

from sklearn.metrics import mean_absolute_error

y_pred_point = xgb.predict(X_test)   # senin normal modelin
mae_point = mean_absolute_error(y_test, y_pred_point)
mae_q50 = mean_absolute_error(y_test, y_q50)

print("Normal XGB MAE:", mae_point)
print("Quantile q=0.50 MAE:", mae_q50)

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

# Eski (squarederror) XGB modelinden test tahmini
y_pred_point = xgb.predict(X_test)

# Quantile q=0.5 modelinden tahmin
y_pred_q50 = y_q50

def evaluate(name, y_true, y_pred):
    mae = mean_absolute_error(y_true, y_pred)
    rmse = mean_squared_error(y_true, y_pred) ** 0.5
    r2 = r2_score(y_true, y_pred)
    print(f"{name:15} → MAE: {mae:.5f}, RMSE: {rmse:.5f}, R²: {r2:.5f}")

evaluate("XGB point", y_test, y_pred_point)
evaluate("XGB q=0.5", y_test, y_pred_q50)

# %90 bandının gerçek kapsaması

inside_band = (y_test >= y_q10) & (y_test <= y_q90)
coverage = inside_band.mean() * 100

print(f"%90 bandının gerçek kapsaması: %{coverage:.2f}")