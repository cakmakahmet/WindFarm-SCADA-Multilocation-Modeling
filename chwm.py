# -*- coding: utf-8 -*-
"""CHWM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lBZDXrzNwYsRLGFuxZAHPS_1WWV2AqMZ
"""

import numpy as np
import pandas as pd
from xgboost import XGBRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

dosya_yolu = "/content/T1_merged_meteo.csv"
df = pd.read_csv(dosya_yolu)

print("Ham veri şekli:", df.shape)
print("Sütunlar:", df.columns.tolist()[:10], "...")

# Time sütununu standardize ettik
df = df.rename(columns={
    "Date/Time": "Time",
    "DATE_TIME": "Time"
})

df["Time"] = pd.to_datetime(df["Time"], errors="coerce")
df = df.sort_values("Time").reset_index(drop=True)

# Power sütununu standardize ettik
df = df.rename(columns={
    "LV ActivePower (kW)": "Power",
    "ActivePower": "Power"
})

print("Standart isimlendirme sonrası sütunlar:", df.columns.tolist())

df = df[df["Power"] > 50].copy()
df = df.dropna(subset=["Power", "Time"]).reset_index(drop=True)
print("Power>50 filtresi sonrası shape:", df.shape)

data = df.copy()

# Power lag / rolling
data["dPower"]       = data["Power"].diff()
data["Power_lag1"]   = data["Power"].shift(1)
data["Power_lag6"]   = data["Power"].shift(6)
data["Power_lag24"]  = data["Power"].shift(24)

data["Power_roll6"]   = data["Power"].shift(1).rolling(6).mean()
data["Power_roll12"]  = data["Power"].shift(1).rolling(12).mean()
data["Power_rollstd6"] = data["Power"].shift(1).rolling(6).std()

# Rüzgar hızı FE
if "Wind Speed (m/s)" in data.columns:
    ws = data["Wind Speed (m/s)"]
    data["dWind"]          = ws.diff()
    data["Wind_rollmean3"] = ws.shift(1).rolling(3).mean()
    data["Wind_rollstd3"]  = ws.shift(1).rolling(3).std()
    data["Wind3"]          = ws**3

# Rüzgar yönü sin/cos
if "Wind Direction (°)" in data.columns:
    wd = data["Wind Direction (°)"]
    rad = np.deg2rad(wd)
    data["wind_sin"] = np.sin(rad)
    data["wind_cos"] = np.cos(rad)

# Zaman FE
data["hour"]      = data["Time"].dt.hour
data["dayofweek"] = data["Time"].dt.dayofweek
data["month"]     = data["Time"].dt.month
data["dayofyear"] = data["Time"].dt.dayofyear

# ERA5 / API meteo FE (varsa)
if "windspeed_100m" in data.columns:
    data["era_ws100"]   = data["windspeed_100m"]
    data["era_ws100_3"] = data["windspeed_100m"]**3

if "windspeed_10m" in data.columns:
    data["era_ws10"] = data["windspeed_10m"]

if "winddirection_10m" in data.columns:
    ang = np.deg2rad(data["winddirection_10m"])
    data["era_wd_sin"] = np.sin(ang)
    data["era_wd_cos"] = np.cos(ang)

if "windgusts_10m" in data.columns:
    data["era_gust"] = data["windgusts_10m"]

if "temperature_2m" in data.columns:
    data["era_temp2"] = data["temperature_2m"]

if "relativehumidity_2m" in data.columns:
    data["era_rh2"] = data["relativehumidity_2m"]

if "dewpoint_2m" in data.columns:
    data["era_dew2"] = data["dewpoint_2m"]

# Hava yoğunluğu (varsa)
R = 287.05
if "pressure_msl" in data.columns and "temperature_2m" in data.columns:
    data["air_density"] = (data["pressure_msl"] * 100) / (R * (data["temperature_2m"] + 273.15))

# Tamamen NaN kolonları attık
data = data.dropna(axis=1, how="all")

# Lag/rolling sebebiyle baştaki satırları attık (örneğin ilk 24)
data = data.iloc[24:].copy()

# Kalan NaN'leri satır bazında temizledik
data = data.dropna().reset_index(drop=True)

print("FE sonrası veri şekli:", data.shape)
print("Toplam feature sayısı:", len(data.columns))

hedef_sutun = "Power"
tarih_sutun = "Time"

feature_cols = [c for c in data.columns if c not in [hedef_sutun, tarih_sutun]]

X = data[feature_cols].values
y = data[hedef_sutun].values

n = len(data)
train_end = int(n * 0.70)
val_end   = int(n * 0.85)

X_train, y_train = X[:train_end], y[:train_end]
X_val,   y_val   = X[train_end:val_end], y[train_end:val_end]
X_test,  y_test  = X[val_end:], y[val_end:]

print(f"Toplam örnek sayısı: {n}")
print(f"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}")
print("Feature sayısı:", X_train.shape[1])

xgb_point = XGBRegressor(
    n_estimators=800,
    learning_rate=0.05,
    max_depth=6,
    subsample=0.9,
    colsample_bytree=0.9,
    objective="reg:squarederror",
    random_state=42,
    n_jobs=-1
)

rf_model = RandomForestRegressor(
    n_estimators=300,
    max_depth=None,
    min_samples_leaf=2,
    random_state=42,
    n_jobs=-1
)

xgb_point.fit(X_train, y_train)
rf_model.fit(X_train, y_train)

y_val_xgb  = xgb_point.predict(X_val)
y_val_rf   = rf_model.predict(X_val)

y_test_xgb = xgb_point.predict(X_test)
y_test_rf  = rf_model.predict(X_test)

alphas = np.linspace(0.0, 1.0, 21)  # 0.00, 0.05, ..., 1.00
best_alpha = None
best_mae = 1e18

for a in alphas:
    y_val_hybrid = a * y_val_xgb + (1 - a) * y_val_rf
    mae = mean_absolute_error(y_val, y_val_hybrid)
    if mae < best_mae:
        best_mae = mae
        best_alpha = a

print(f"Seçilen alpha (XGB ağırlığı): {best_alpha:.2f} | Val MAE (hybrid): {best_mae:.3f}")

y_test_hybrid_point = best_alpha * y_test_xgb + (1 - best_alpha) * y_test_rf

n_trees = len(rf_model.estimators_)
print("RF ağaç sayısı:", n_trees)

# 1) Her ağaç için TEST tahmini → (n_samples, n_trees)
all_tree_preds_test = np.zeros((X_test.shape[0], n_trees))

for i, tree in enumerate(rf_model.estimators_):
    all_tree_preds_test[:, i] = tree.predict(X_test)

# 2) Quantile hesapla
q_low, q_high = 0.05, 0.95
y_q05_test = np.quantile(all_tree_preds_test, q_low, axis=1)
y_q95_test = np.quantile(all_tree_preds_test, q_high, axis=1)

# 3) Coverage (gerçek değer bandın içinde mi?)
inside_band = (y_test >= y_q05_test) & (y_test <= y_q95_test)
coverage = inside_band.mean() * 100

print(f"RF %90 bandının TEST kapsaması: %{coverage:.2f}")

# 4) Band genişliği (upper - lower)
band_width = y_q95_test - y_q05_test

# Ortalama bant genişliği
print(f"RF band ortalama genişliği (kW): {band_width.mean():.3f}")

# Medyan bant genişliği
print(f"RF band medyan genişliği (kW): {np.median(band_width):.3f}")

def evaluate(name, y_true, y_pred):
    mae  = mean_absolute_error(y_true, y_pred)
    rmse = mean_squared_error(y_true, y_pred) ** 0.5
    r2   = r2_score(y_true, y_pred)
    print(f"{name:<18} → MAE: {mae:8.3f}, RMSE: {rmse:8.3f}, R²: {r2:7.4f}")

print("\n TEST SONUÇLARI (POINT)")
evaluate("XGB point",    y_test, y_test_xgb)
evaluate("RF point",     y_test, y_test_rf)
evaluate("HYBRID point", y_test, y_test_hybrid_point)

print("\n TEST SONUÇLARI (PROBABILISTIC)")
print("RF q05–q95 band coverage ve band genişliği yukarıda yazıldı.")

import pandas as pd

X_test_df = pd.DataFrame(X_test, columns=feature_cols)

import shap

explainer = shap.TreeExplainer(xgb_point)
# Tüm test seti yerine %20-30’unu aldık
X_sample = X_test_df.sample(n=2000, random_state=42)

shap.summary_plot(shap_values, X_sample, feature_names=feature_cols)

import numpy as np

# Mean(|SHAP|) bazlı global önem
mean_abs_shap = np.mean(np.abs(shap_values), axis=0)

fi_shap = pd.DataFrame({
    "Feature": feature_cols,
    "MeanAbsSHAP": mean_abs_shap
}).sort_values("MeanAbsSHAP", ascending=False)

print(fi_shap.head(20))

top_n = 12
top_features = fi_shap["Feature"].head(top_n).tolist()

for feat in top_features:
    print("Feature:", feat)
    shap.dependence_plot(feat, shap_values, X_sample, feature_names=feature_cols)